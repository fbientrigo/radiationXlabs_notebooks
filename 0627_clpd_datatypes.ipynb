{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "433f893e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from ROOT import TFile, TTree, array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1484351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/fabian/.pyenv/versions/root-py3112/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41594bd",
   "metadata": {},
   "source": [
    "## Lectura de Ficheros\n",
    "\n",
    "Se denotan las columnas 'time', 'lfsrTMR', 'B0', 'B1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1625184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Líneas descartadas por parseo: 20241\n",
      "Bad_records registrados (ts ≥ 2022-01-01): 20235\n",
      "Líneas descartadas por ts inválido: 6\n",
      "\n",
      "Errores por día (filtrados):\n",
      "         date  bad_lines\n",
      "0  2022-11-09       6448\n",
      "1  2022-11-10       1881\n",
      "2  2022-11-11       2544\n",
      "3  2022-11-12        631\n",
      "4  2022-11-13       4644\n",
      "5  2022-11-14       1602\n",
      "6  2022-11-15       2485\n",
      "\n",
      "Errores por hora (filtrados):\n",
      "                   hour  bad_lines\n",
      "0   2022-11-09 11:00:00         14\n",
      "1   2022-11-09 12:00:00         85\n",
      "2   2022-11-09 13:00:00        111\n",
      "3   2022-11-09 14:00:00        940\n",
      "4   2022-11-09 15:00:00       1659\n",
      "..                  ...        ...\n",
      "101 2022-11-15 06:00:00         39\n",
      "102 2022-11-15 07:00:00       1834\n",
      "103 2022-11-15 08:00:00         31\n",
      "104 2022-11-15 09:00:00          1\n",
      "105 2022-11-15 10:00:00          1\n",
      "\n",
      "[106 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Función parse_message actualizada (igual que antes)\n",
    "def parse_message(raw: str):\n",
    "    line = raw.replace('*', '').replace(' #', ',').strip()\n",
    "    parts = line.split(',')\n",
    "    if len(parts) < 4 or len(parts[2]) != 4 or len(parts[3]) != 4:\n",
    "        raise ValueError(\"Formato inválido\")\n",
    "    ts = float(parts[0])\n",
    "    time = datetime.utcfromtimestamp(ts) + timedelta(hours=2)\n",
    "    lfsr = int(parts[1])\n",
    "    b0, b1 = parts[2], parts[3]\n",
    "    return time, lfsr, b0, b1\n",
    "\n",
    "def count_fails(hex_str: str) -> int:\n",
    "    \"\"\"\n",
    "    Convierte hex_str a entero, aplica máscara y negación,\n",
    "    cuenta bits a '1' en los 8 bits superiores.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        val = int(hex_str, 16)\n",
    "        masked = (~val & 0xFF00) >> 8\n",
    "        # Conteo de bits\n",
    "        return bin(masked).count('1')\n",
    "    except ValueError:\n",
    "        return 0  # En caso de error de parseo\n",
    "    \n",
    "def compute_periodic(counts: list[int], window: int = 3) -> int:\n",
    "    \"\"\"\n",
    "    Detecta patrones de incremento repetido en 'counts'.\n",
    "    Retorna el número de patrones periódicos encontrados.\n",
    "    \"\"\"\n",
    "    periodic = 0\n",
    "    for i in range(window, len(counts)):\n",
    "        if (counts[i]   == counts[i-1] + 1 and\n",
    "            counts[i-1] == counts[i-2]     and\n",
    "            counts[i-2] == counts[i-3] + 1 ):\n",
    "            periodic += 1\n",
    "    return periodic\n",
    "\n",
    "# -- lectura ---\n",
    "ts_threshold = datetime(2022, 1, 1) # threshold, no tendría sentido datos previo a esto\n",
    "fnames = glob.glob('../0_raw/Campaign3/cpld/run/cpld_data_*.dat')\n",
    "records = []\n",
    "bad_records = []\n",
    "bad_count = 0\n",
    "drops_invalid_ts = 0\n",
    "last_ts = None\n",
    "\n",
    "for fn in fnames:\n",
    "    text = open(fn).read().replace('*', '').replace(' #', '')\n",
    "    for raw in text.splitlines():\n",
    "        # Extraer timestamp bruto\n",
    "        parts = raw.split(',')\n",
    "        try:\n",
    "            ts_cand = float(parts[0])\n",
    "            last_ts = datetime.utcfromtimestamp(ts_cand) + timedelta(hours=2)\n",
    "        except:\n",
    "            pass  # mantenemos el último válido\n",
    "\n",
    "        # Intentar parseo completo\n",
    "        try:\n",
    "            time, lfsr, b0, b1 = parse_message(raw)\n",
    "            records.append((time, lfsr, b0, b1))\n",
    "        except Exception:\n",
    "            bad_count += 1\n",
    "            # Solo registramos si last_ts es válido y supera el umbral\n",
    "            if last_ts and last_ts >= ts_threshold:\n",
    "                bad_records.append({\"ts\": last_ts})\n",
    "            else:\n",
    "                drops_invalid_ts += 1\n",
    "            continue\n",
    "\n",
    "# Construir DataFrame\n",
    "df = pd.DataFrame(records, columns=['time', 'lfsrTMR', 'B0', 'B1'])\n",
    "df.sort_values('time', inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Error DF\n",
    "print(f\"Líneas descartadas por parseo: {bad_count}\")\n",
    "print(f\"Bad_records registrados (ts ≥ {ts_threshold.date()}): {len(bad_records)}\")\n",
    "print(f\"Líneas descartadas por ts inválido: {drops_invalid_ts}\")\n",
    "\n",
    "# Crear DataFrame de bad_records y agrupar\n",
    "df_bad = pd.DataFrame(bad_records)\n",
    "df_bad['date'] = df_bad['ts'].dt.date\n",
    "errors_por_dia = df_bad.groupby('date').size().reset_index(name='bad_lines')\n",
    "\n",
    "df_bad['hour'] = df_bad['ts'].dt.floor('h')\n",
    "errors_por_hora = df_bad.groupby('hour').size().reset_index(name='bad_lines')\n",
    "\n",
    "# Resultados\n",
    "print(\"\\nErrores por día (filtrados):\")\n",
    "print(errors_por_dia)\n",
    "\n",
    "print(\"\\nErrores por hora (filtrados):\")\n",
    "print(errors_por_hora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e303f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1101639"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54ae0ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Número total de muestras: 1081006\n",
      "[1] Conversión hex→uint16: 0.49s\n",
      "[2] Enmascarado de bytes altos: 0.00s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\n",
    "# Patrón para 4 dígitos hexadecimales\n",
    "hex_pat = re.compile(r'^[0-9A-Fa-f]{4}$')\n",
    "valid_mask = ( # Filtrar el DataFrame original\n",
    "    df['B0'].astype(str).str.fullmatch(hex_pat.pattern) &\n",
    "    df['B1'].astype(str).str.fullmatch(hex_pat.pattern)\n",
    ")\n",
    "df_valid = df[valid_mask].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# --- Medidor de tiempo total ---\n",
    "t_start = time.perf_counter()\n",
    "\n",
    "# ------------------------------------ Información inicial\n",
    "n_samples = len(df_valid)\n",
    "print(f\"[0] Número total de muestras: {n_samples}\")\n",
    "\n",
    "# Convertir columnas hex a uint16 a manera de tener el valor de los bits cambiados\n",
    "t1 = time.perf_counter()\n",
    "b0_int = df_valid['B0'].apply(lambda s: int(s, 16)).to_numpy(dtype=np.uint16)\n",
    "b1_int = df_valid['B1'].apply(lambda s: int(s, 16)).to_numpy(dtype=np.uint16)\n",
    "print(f\"[1] Conversión hex→uint16: {time.perf_counter() - t1:.2f}s\")\n",
    "\n",
    "\n",
    "# Aplicar máscara y extraer byte alto\n",
    "t2 = time.perf_counter()\n",
    "masked0 = ((~b0_int) & 0xFF00) >> 8\n",
    "masked1 = ((~b1_int) & 0xFF00) >> 8\n",
    "print(f\"[2] Enmascarado de bytes altos: {time.perf_counter() - t2:.2f}s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d6ce050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] Unpack de bits por byte: 0.01s\n",
      "(1081006, 16)\n",
      "[4] Concatenación de bits0+b1: 0.01s\n",
      "(1081006,)\n",
      "[5] Conteo instantáneo de fallas: 0.02s\n",
      "[6] Detección de resets (29574 encontrados): 0.00s\n",
      "[7] Cálculo de acumulado ajustado: 6.09s\n",
      "[8] Conteo de flancos de subida por bit: 0.39s\n",
      "  - Procesando patrón periódico para bit 0/15\n",
      "  - Procesando patrón periódico para bit 4/15\n",
      "  - Procesando patrón periódico para bit 8/15\n",
      "  - Procesando patrón periódico para bit 12/15\n",
      "[9] Detección de errores periódicos: 0.55s\n",
      "[10] Escritura en DataFrame: 0.28s\n",
      "Tiempo total aproximado: 12.59s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------------Desplegar bits: matriz (n_muestras × 8) para cada byte\n",
    "t3 = time.perf_counter()\n",
    "\n",
    "masked0_uint8 = masked0.astype(np.uint8)          # shape: (N,)\n",
    "masked1_uint8 = masked1.astype(np.uint8)          # shape: (N,)\n",
    "# expandir dimensión para que unpackbits opere por fila\n",
    "masked0_2d = masked0_uint8[:, np.newaxis]         # shape: (N,1)\n",
    "masked1_2d = masked1_uint8[:, np.newaxis]         # shape: (N,1)\n",
    "\n",
    "# desempacar bits little-endian a lo largo de cada fila → (N,8)\n",
    "bits0 = np.unpackbits(masked0_2d, axis=1, bitorder='little')  # shape: (N,8)\n",
    "bits1 = np.unpackbits(masked1_2d, axis=1, bitorder='little')  # shape: (N,8)\n",
    "\n",
    "# legacy\n",
    "# bits0 = np.unpackbits(masked0.view(np.uint8), axis=0, bitorder='little')[:, :8]\n",
    "# bits1 = np.unpackbits(masked1.view(np.uint8), axis=0, bitorder='little')[:, :8]\n",
    "\n",
    "print(f\"[3] Unpack de bits por byte: {time.perf_counter() - t3:.2f}s\")\n",
    "\n",
    "# 4. Concatenar para obtener (n_muestras × 16)\n",
    "t4 = time.perf_counter()\n",
    "bits = np.hstack([bits0, bits1]).astype(bool) \n",
    "print(bits.shape)  \n",
    "print(f\"[4] Concatenación de bits0+b1: {time.perf_counter() - t4:.2f}s\")\n",
    "\n",
    "# 5. Conteo instantáneo de fallas (popcount)\n",
    "t5 = time.perf_counter()\n",
    "fails_inst = bits.sum(axis=1)\n",
    "print(fails_inst.shape)\n",
    "print(f\"[5] Conteo instantáneo de fallas: {time.perf_counter() - t5:.2f}s\")\n",
    "\n",
    "# 6. Detección de resets para bias\n",
    "t6 = time.perf_counter()\n",
    "resets = (fails_inst == 0) & (np.concatenate([[False], fails_inst[:-1] > 0]))\n",
    "reset_indices = np.nonzero(resets)[0]\n",
    "print(f\"[6] Detección de resets ({len(reset_indices)} encontrados): {time.perf_counter() - t6:.2f}s\")\n",
    "\n",
    "# 7. Cálculo de acumulado ajustado\n",
    "t7 = time.perf_counter()\n",
    "cumsum = fails_inst.cumsum()\n",
    "bias_array = np.zeros_like(cumsum)\n",
    "for idx in reset_indices:\n",
    "    bias_array[idx:] += cumsum[idx - 1]\n",
    "fails_acum = np.maximum.accumulate(cumsum + bias_array)\n",
    "print(f\"[7] Cálculo de acumulado ajustado: {time.perf_counter() - t7:.2f}s\")\n",
    "\n",
    "# 8. Conteo de flancos de subida (edges) y acumulado por bit\n",
    "t8 = time.perf_counter()\n",
    "prev = np.vstack([np.zeros((1, 16), bool), bits[:-1]])\n",
    "edges = bits & (~prev)\n",
    "bit_counts = edges.cumsum(axis=0)\n",
    "print(f\"[8] Conteo de flancos de subida por bit: {time.perf_counter() - t8:.2f}s\")\n",
    "\n",
    "# 9. Detección de errores periódicos por bit\n",
    "t9 = time.perf_counter()\n",
    "kernel = np.array([1, 0, 1])\n",
    "bit_periodic = np.zeros_like(bit_counts, dtype=int)\n",
    "\n",
    "for k in range(16):\n",
    "    # 1) Calcular la convolución en modo 'valid'\n",
    "    conv = np.convolve(bit_counts[:, k], kernel, mode='valid')  # longitud = N-2\n",
    "\n",
    "    # 2) Calcular cumsum solo donde conv == 2\n",
    "    periodic_cumsum = (conv == 2).cumsum()  # longitud = N-2\n",
    "\n",
    "    # 3) Alinear y asignar a bit_periodic:\n",
    "    #    conv[i] corresponde al bit de error periódico en la muestra i+2,\n",
    "    #    así que asignamos desde bit_periodic[2:, k]\n",
    "    bit_periodic[2:, k] = periodic_cumsum\n",
    "\n",
    "    if k % 4 == 0:\n",
    "        print(f\"  - Procesando patrón periódico para bit {k}/15\")\n",
    "print(f\"[9] Detección de errores periódicos: {time.perf_counter() - t9:.2f}s\")\n",
    "\n",
    "# --- Asignar resultados de vuelta a df_valid ---\n",
    "t10 = time.perf_counter()\n",
    "df_valid['fails_inst'] = fails_inst\n",
    "df_valid['fails_acum'] = fails_acum\n",
    "for k in range(16):\n",
    "    df_valid[f'bitn{k}']  = bit_counts[:, k]\n",
    "    df_valid[f'bitnP{k}'] = bit_periodic[:, k]\n",
    "print(f\"[10] Escritura en DataFrame: {time.perf_counter() - t10:.2f}s\")\n",
    "\n",
    "# --- Tiempo total ---\n",
    "print(f\"Tiempo total aproximado: {time.perf_counter() - t_start:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7368934",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff63524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbd1c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94183ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas removidas por hex inválido: 20633/1101639 = 0.018729365971974485\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 56\u001b[39m\n\u001b[32m     54\u001b[39m     bit_counts[k][i]   = bit_cum[k]\n\u001b[32m     55\u001b[39m     \u001b[38;5;66;03m# Suponiendo compute_periodic definido antes\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     bit_periodic[k][i] = \u001b[43mcompute_periodic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbit_counts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m     bit_prev[k] = bits[k]\n\u001b[32m     59\u001b[39m fails_inst.append(total)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line -1\u001b[39m, in \u001b[36mcompute_periodic\u001b[39m\u001b[34m(counts, window)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# --- codigo old, demora 2 horas quizas ----\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Patrón para 4 dígitos hexadecimales\n",
    "hex_pat = re.compile(r'^[0-9A-Fa-f]{4}$')\n",
    "\n",
    "# Filtrar el DataFrame original\n",
    "valid_mask = (\n",
    "    df['B0'].astype(str).str.fullmatch(hex_pat.pattern) &\n",
    "    df['B1'].astype(str).str.fullmatch(hex_pat.pattern)\n",
    ")\n",
    "df_valid = df[valid_mask].reset_index(drop=True)\n",
    "bad_hex_rows = len(df) - len(df_valid)\n",
    "print(f\"Filas removidas por hex inválido: {bad_hex_rows}/{len(df)} = {bad_hex_rows/len(df)}\")\n",
    "\n",
    "# Inicializar contadores sobre df_valid\n",
    "Nbits = 16\n",
    "fails_inst = []\n",
    "fails_acum = []\n",
    "bit_counts   = [[0]*len(df_valid) for _ in range(Nbits)]\n",
    "bit_periodic = [[0]*len(df_valid) for _ in range(Nbits)]\n",
    "bias = 0\n",
    "cum_total = 0\n",
    "bit_cum  = [0]*Nbits\n",
    "bit_prev = [0]*Nbits\n",
    "\n",
    "# Función para conteo rápido de bits\n",
    "def count_ones_upper_byte(hex_str):\n",
    "    val = int(hex_str, 16)\n",
    "    return bin((~val & 0xFF00) >> 8).count('1')\n",
    "\n",
    "# Bucle de cómputo sin desbordes\n",
    "for i, row in df_valid.iterrows():\n",
    "    f0 = count_ones_upper_byte(row['B0'])\n",
    "    f1 = count_ones_upper_byte(row['B1'])\n",
    "    total = f0 + f1\n",
    "\n",
    "    # Ajuste de bias sobre la última entrada válida\n",
    "    if fails_inst and total == 0 and fails_inst[-1] != 0:\n",
    "        bias = fails_acum[-1]\n",
    "    cum_total = max(cum_total + total, cum_total, total + bias)\n",
    "\n",
    "    # Conteo por bit\n",
    "    masked0 = ((~int(row['B0'], 16)) & 0xFF00) >> 8\n",
    "    masked1 = ((~int(row['B1'], 16)) & 0xFF00) >> 8\n",
    "    bits = [(masked0 >> k) & 1 for k in range(8)] + [(masked1 >> k) & 1 for k in range(8)]\n",
    "\n",
    "    for k in range(Nbits):\n",
    "        if bit_prev[k] == 0 and bits[k] == 1:\n",
    "            bit_cum[k] += 1\n",
    "        bit_counts[k][i]   = bit_cum[k]\n",
    "        # Suponiendo compute_periodic definido antes\n",
    "        bit_periodic[k][i] = compute_periodic(bit_counts[k][:i+1])\n",
    "        bit_prev[k] = bits[k]\n",
    "\n",
    "    fails_inst.append(total)\n",
    "    fails_acum.append(cum_total)\n",
    "\n",
    "# Agregar resultados al DataFrame válido\n",
    "df_valid['fails_inst'] = fails_inst\n",
    "df_valid['fails_acum'] = fails_acum\n",
    "for k in range(Nbits):\n",
    "    df_valid[f'bitn{k}']  = bit_counts[k]\n",
    "    df_valid[f'bitnP{k}'] = bit_periodic[k]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085e84d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar al DataFrame\n",
    "df['fails_inst'] = fails_inst\n",
    "df['fails_acum'] = fails_acum\n",
    "for k in range(Nbits):\n",
    "    df[f'bitn{k}'] = bit_counts[k]\n",
    "    df[f'bitnP{k}'] = bit_periodic[k]\n",
    "\n",
    "# 4. Generación de gráficos\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "for k in range(Nbits):\n",
    "    plt.plot(df['time'], df[f'bitn{k}'], linestyle='--', marker='.', label=f'bit{k}')\n",
    "plt.xlabel('Tiempo')\n",
    "plt.ylabel('Errores acumulados por bit')\n",
    "plt.legend(ncol=4)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5. Escritura de ROOT TTree\n",
    "\n",
    "ofile = TFile(\"cpld_data.root\", 'RECREATE')\n",
    "tree = TTree(\"tr\", \"CPLD data\")\n",
    "t_arr = array('d', [0.0])\n",
    "b_arr = array('i', Nbits*[0])\n",
    "bP_arr = array('i', Nbits*[0])\n",
    "\n",
    "tree.Branch(\"t\", t_arr, \"t/D\")\n",
    "tree.Branch(\"bit\", b_arr, f\"bit[{Nbits}]/I\")\n",
    "tree.Branch(\"bitP\", bP_arr, f\"bitP[{Nbits}]/I\")\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    t_arr[0] = (row['time'] - datetime(1970,1,1)).total_seconds()\n",
    "    for k in range(Nbits):\n",
    "        b_arr[k] = row[f'bitn{k}']\n",
    "        bP_arr[k] = row[f'bitnP{k}']\n",
    "    tree.Fill()\n",
    "\n",
    "ofile.Write()\n",
    "ofile.Close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca971ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "504fdab1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 16: 'FF#0'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     21\u001b[39m cum_total = \u001b[38;5;28mmax\u001b[39m(cum_total + total, cum_total, total + bias)\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Conteo por bit\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m masked0 = ((~\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mB0\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m)\u001b[49m) & \u001b[32m0xFF00\u001b[39m) >> \u001b[32m8\u001b[39m\n\u001b[32m     25\u001b[39m masked1 = ((~\u001b[38;5;28mint\u001b[39m(row[\u001b[33m'\u001b[39m\u001b[33mB1\u001b[39m\u001b[33m'\u001b[39m],\u001b[32m16\u001b[39m)) & \u001b[32m0xFF00\u001b[39m) >> \u001b[32m8\u001b[39m\n\u001b[32m     26\u001b[39m bits = [(masked0>>k)&\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m8\u001b[39m)] + [(masked1>>k)&\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m8\u001b[39m)]\n",
      "\u001b[31mValueError\u001b[39m: invalid literal for int() with base 16: 'FF#0'"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3. Cálculo de errores instantáneos y acumulados\n",
    "\n",
    "Nbits = 16\n",
    "fails_inst = []\n",
    "fails_acum = []\n",
    "bit_counts = [[0]*len(df) for _ in range(Nbits)]\n",
    "bit_periodic = [[0]*len(df) for _ in range(Nbits)]\n",
    "\n",
    "bias = 0\n",
    "cum_total = 0\n",
    "bit_cum = [0]*Nbits\n",
    "bit_prev = [0]*Nbits\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    f0 = count_fails(row['B0'])\n",
    "    f1 = count_fails(row['B1'])\n",
    "    total = f0 + f1\n",
    "    # Ajuste de bias si reset detectado\n",
    "    if i>0 and total == 0 and (fails_inst[i-1] != 0):\n",
    "        bias = fails_acum[i-1]\n",
    "    cum_total = max(cum_total + total, cum_total, total + bias)\n",
    "    \n",
    "    # Conteo por bit\n",
    "    masked0 = ((~int(row['B0'],16)) & 0xFF00) >> 8\n",
    "    masked1 = ((~int(row['B1'],16)) & 0xFF00) >> 8\n",
    "    bits = [(masked0>>k)&1 for k in range(8)] + [(masked1>>k)&1 for k in range(8)]\n",
    "    \n",
    "    for k in range(Nbits):\n",
    "        # Detectar flancos de subida para conteo\n",
    "        if bit_prev[k]==0 and bits[k]==1:\n",
    "            bit_cum[k] += 1\n",
    "        bit_counts[k][i] = bit_cum[k]\n",
    "        # Patrón periódico\n",
    "        bit_periodic[k][i] = compute_periodic(bit_counts[k][:i+1])\n",
    "        bit_prev[k] = bits[k]\n",
    "    \n",
    "    fails_inst.append(total)\n",
    "    fails_acum.append(cum_total)\n",
    "\n",
    "# Agregar al DataFrame\n",
    "df['fails_inst'] = fails_inst\n",
    "df['fails_acum'] = fails_acum\n",
    "for k in range(Nbits):\n",
    "    df[f'bitn{k}'] = bit_counts[k]\n",
    "    df[f'bitnP{k}'] = bit_periodic[k]\n",
    "\n",
    "# 4. Generación de gráficos\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "for k in range(Nbits):\n",
    "    plt.plot(df['time'], df[f'bitn{k}'], linestyle='--', marker='.', label=f'bit{k}')\n",
    "plt.xlabel('Tiempo')\n",
    "plt.ylabel('Errores acumulados por bit')\n",
    "plt.legend(ncol=4)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5. Escritura de ROOT TTree\n",
    "\n",
    "ofile = TFile(\"cpld_data.root\", 'RECREATE')\n",
    "tree = TTree(\"tr\", \"CPLD data\")\n",
    "t_arr = array('d', [0.0])\n",
    "b_arr = array('i', Nbits*[0])\n",
    "bP_arr = array('i', Nbits*[0])\n",
    "\n",
    "tree.Branch(\"t\", t_arr, \"t/D\")\n",
    "tree.Branch(\"bit\", b_arr, f\"bit[{Nbits}]/I\")\n",
    "tree.Branch(\"bitP\", bP_arr, f\"bitP[{Nbits}]/I\")\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    t_arr[0] = (row['time'] - datetime(1970,1,1)).total_seconds()\n",
    "    for k in range(Nbits):\n",
    "        b_arr[k] = row[f'bitn{k}']\n",
    "        bP_arr[k] = row[f'bitnP{k}']\n",
    "    tree.Fill()\n",
    "\n",
    "ofile.Write()\n",
    "ofile.Close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8766f5f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "root-py3112",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
